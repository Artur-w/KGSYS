{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('CS440': pipenv)",
   "display_name": "Python 3.8.6 64-bit ('CS440': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "71d9b2d2b138315642c3d2803d195d9bcd3118ef1171278ec8163cc95a3a17a5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Information Extraction techniques\n",
    "https://www.analyticsvidhya.com/blog/2020/06/nlp-project-information-extraction/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Year         Country                                             Speech  \\\n",
       "0  2018  data/dataverse  On my own behalf and on behalf of my country, ...   \n",
       "1  1974  data/dataverse  Mr. President, I have already had occasion to ...   \n",
       "2  1995  data/dataverse  It gives me great pleasure to\\ncongratulate Mr...   \n",
       "3  2009  data/dataverse  I offer my congratulations \\nto Mr. Treki on h...   \n",
       "4  1996  data/dataverse  ﻿It gives me great pleasure to\\ncongratulate A...   \n",
       "\n",
       "  Session  \n",
       "0      73  \n",
       "1      29  \n",
       "2      50  \n",
       "3      64  \n",
       "4      51  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Country</th>\n      <th>Speech</th>\n      <th>Session</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018</td>\n      <td>data/dataverse</td>\n      <td>On my own behalf and on behalf of my country, ...</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1974</td>\n      <td>data/dataverse</td>\n      <td>Mr. President, I have already had occasion to ...</td>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1995</td>\n      <td>data/dataverse</td>\n      <td>It gives me great pleasure to\\ncongratulate Mr...</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2009</td>\n      <td>data/dataverse</td>\n      <td>I offer my congratulations \\nto Mr. Treki on h...</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1996</td>\n      <td>data/dataverse</td>\n      <td>﻿It gives me great pleasure to\\ncongratulate A...</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Folder path\n",
    "folders = glob.glob('data/dataverse_files/Converted sessions/Session*')\n",
    "\n",
    "\n",
    "# Dataframe\n",
    "df = pd.DataFrame(columns={'Country','Speech','Session','Year'})\n",
    "\n",
    "# Read speeches by India\n",
    "i = 0 \n",
    "for file in folders:\n",
    "    \n",
    "    speech = glob.glob(file+'/IND*.txt')\n",
    "\n",
    "    with open(speech[0],encoding='utf8') as f:\n",
    "        # Speech\n",
    "        df.loc[i,'Speech'] = f.read()\n",
    "        # Year \n",
    "        df.loc[i,'Year'] = speech[0].split('_')[-1].split('.')[0]\n",
    "        # Session\n",
    "        df.loc[i,'Session'] = speech[0].split('_')[-2]\n",
    "        # Country\n",
    "        df.loc[i,'Country'] = speech[0].split('_')[0].split(\"\\\\\")[-1]\n",
    "        # Increment counter\n",
    "        i += 1 \n",
    "        \n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Speech Text Pre-Processing \n",
    "First, we need to clean our text data of unwanted characters(newline, hyphen, alutations, apostrophes)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning speeches\n",
    "# no lemmatization used or change of caps, it could change POS tag of a word\n",
    "\n",
    "def clean(text):\n",
    "\n",
    "    # removing paragraph numbers\n",
    "    text = re.sub('[0-9]+.\\t','',str(text))\n",
    "    # removing new line characters\n",
    "    text = re.sub('\\n ','',str(text))\n",
    "    text = re.sub('\\n',' ',str(text))\n",
    "    # removing apostrophes\n",
    "    text = re.sub(\"'s\",'',str(text))\n",
    "    # removing hyphens\n",
    "    text = re.sub(\"-\",' ',str(text))\n",
    "    text = re.sub(\"- \",'',str(text))\n",
    "    # removing quotation marks\n",
    "    text = re.sub('\\\"','',str(text))\n",
    "    # removing salutations\n",
    "    text = re.sub(\"Mr\\.\",'Mr',str(text))\n",
    "    text = re.sub(\"Mrs\\.\",'Mrs',str(text))\n",
    "    # removing any reference to outside text \n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", str(text))\n",
    "\n",
    "    return text\n",
    "\n",
    "# preprocessing speeches\n",
    "df['Speech_clean'] = df['Speech'].apply(clean)"
   ]
  },
  {
   "source": [
    "## Split the Speech into Different Sentences\n",
    "Splitting into separate sentences will allow us to extract infromation from each sentencee."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split sentences\n",
    "def sentences(text):\n",
    "    # split sentences and questions\n",
    "    text = re.split('[.?]', text)\n",
    "    clean_sent = []\n",
    "    for sent in text:\n",
    "        clean_sent.append(sent)\n",
    "    return clean_sent\n",
    "\n",
    "# sentence\n",
    "df['sent'] = df['Speech_clean'].apply(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe containing sentences\n",
    "df2 = pd.DataFrame(columns=['Sent','Year','Len'])\n",
    "\n",
    "row_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for sent in df.loc[i, 'sent']:\n",
    "\n",
    "        wordcount = len(sent.split())\n",
    "        year = df.loc[i, 'Year']\n",
    "\n",
    "        dict1 = {'Year': year, 'Sent': sent, 'Len': wordcount}\n",
    "        row_list.append(dict1)\n",
    "        \n",
    "df2 = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Year                                               Sent  Len\n",
       "0  2018  On my own behalf and on behalf of my country, ...   35\n",
       "1  2018   As a woman, I feel doubly proud that this hon...   15\n",
       "2  2018   I also recall, with equal pride, that the fir...   34\n",
       "3  2018   I also thank former President Miroslav Lajčák...   19\n",
       "4  2018   We  received the   tragic   news   this   mor...   16"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>Sent</th>\n      <th>Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018</td>\n      <td>On my own behalf and on behalf of my country, ...</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018</td>\n      <td>As a woman, I feel doubly proud that this hon...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018</td>\n      <td>I also recall, with equal pride, that the fir...</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018</td>\n      <td>I also thank former President Miroslav Lajčák...</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018</td>\n      <td>We  received the   tragic   news   this   mor...</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "source": [
    "## Information Extraction using SpaCy\n",
    "we will use SpaCy library for Information Extraction it has all the necessary tools."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "import visualise_spacy_tree\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load english language model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])"
   ]
  },
  {
   "source": [
    "## Information Extraction #1 - Finding mentions of Prime Minister in the speech\n",
    "\n",
    "When working on information extraction tasks, it is important to manualy go over a subset of the dataset to understand what the text is like and determine if anything catches your attention at first glance. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let me walk you through this pattern:\n",
    "\n",
    "- Here, each dictionary in the list matches a unique word\n",
    "- The first and second dictionaries match the keyword “Prime Minister” irrespective of whether it is in uppercase or not, which is why I have included the key “LOWER”\n",
    "- The third dictionary matches a word that is a preposition. What I am looking for here is the word “of”. Now, as discussed before, it may or may not be present in the pattern, therefore, an additional key, “OP” or optional, is mentioned to point out just that\n",
    "- Finally, the last dictionary in the pattern should be a proper noun. This can either be the name of the country or the name of the prime minister\n",
    "- The matched keywords have to be in continuation otherwise the pattern will not match the phrase"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find sentences containing PMs of India\n",
    "def find_names(text):\n",
    "    \n",
    "    names = []\n",
    "    \n",
    "    # spacy doc\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # pattern\n",
    "    pattern = [{'LOWER':'prime'},\n",
    "              {'LOWER':'minister'},\n",
    "              {'POS':'ADP','OP':'?'},\n",
    "              {'POS':'PROPN'}]\n",
    "                \n",
    "    # Matcher class object \n",
    "    matcher = Matcher(nlp.vocab) \n",
    "    matcher.add(\"names\", None, pattern) \n",
    "\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    # finding patterns in the text\n",
    "    for i in range(0,len(matches)):\n",
    "        \n",
    "        # match: id, start, end\n",
    "        token = doc[matches[i][1]:matches[i][2]]\n",
    "        # append token to list\n",
    "        names.append(str(token))\n",
    "    \n",
    "    # Only keep sentences containing Indian PMs\n",
    "    for name in names:\n",
    "        if (name.split()[2] == 'of') and (name.split()[3] != \"India\"):\n",
    "                names.remove(name)\n",
    "            \n",
    "    return names\n",
    "\n",
    "# apply function\n",
    "df2['PM_Names'] = df2['Sent'].apply(find_names)"
   ]
  },
  {
   "source": [
    "## Information Extraction #2 - Finding Initiatives\n",
    "refer to all the schemes, initiatives, conferences, programmes, etc. keywords as initiatives."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if keyswords like 'programs','schemes', etc. present in sentences\n",
    "\n",
    "def prog_sent(text):\n",
    "\n",
    "        patterns = [r'\\b(?i)'+'plan'+r'\\b',\n",
    "               r'\\b(?i)'+'programme'+r'\\b',\n",
    "               r'\\b(?i)'+'scheme'+r'\\b',\n",
    "               r'\\b(?i)'+'campaign'+r'\\b',\n",
    "               r'\\b(?i)'+'initiative'+r'\\b',\n",
    "               r'\\b(?i)'+'conference'+r'\\b',\n",
    "               r'\\b(?i)'+'agreement'+r'\\b',\n",
    "               r'\\b(?i)'+'alliance'+r'\\b']\n",
    "\n",
    "        output = []\n",
    "        flag = 0\n",
    "        for pat in patterns:\n",
    "            if re.search(pat, text) != None:\n",
    "                flag = 1\n",
    "                break\n",
    "        return flag\n",
    "# apply function\n",
    "df2['Check_Scheme'] = df2['Sent'].apply(prog_sent)"
   ]
  },
  {
   "source": [
    " proper noun that starts with a determiner and ends with either ‘initiative’/’programme’/’agreement’ etc. words in the end. t also includes an occasional preposition in the middle."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract initiatives using pattern matching\n",
    "def all_schemes(text, check):\n",
    "    schemes = []\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # initiatives\n",
    "    prog_list = ['programme','scheme',\n",
    "                 'initiative','campaign',\n",
    "                 'agreement','conference',\n",
    "                 'alliance','plan']\n",
    "    \n",
    "    # pattern to match initiatives names \n",
    "    pattern = [{'POS':'DET'},\n",
    "               {'POS':'PROPN','DEP':'compound'},\n",
    "               {'POS':'PROPN','DEP':'compound'},\n",
    "               {'POS':'PROPN','OP':'?'},\n",
    "               {'POS':'PROPN','OP':'?'},\n",
    "               {'POS':'PROPN','OP':'?'},\n",
    "               {'LOWER':{'IN':prog_list},'OP':'+'}\n",
    "              ]\n",
    "\n",
    "    if check == 0:\n",
    "        # return blank list\n",
    "        return schemes\n",
    "\n",
    "    # Matcher class object\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"matching\", None, pattern)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    for i in range(0, len(matches)):\n",
    "        # match: id, start, end\n",
    "        start, end = matches[i][1], matches[i][2]\n",
    "\n",
    "        if doc[start].pos_ == 'DET':\n",
    "            start = start +1\n",
    "\n",
    "        # matched string\n",
    "        span = str(doc[start:end])\n",
    "\n",
    "        if (len(schemes)!=0) and (schemes[-1] in span):\n",
    "            schemes[-1] = span\n",
    "        else:\n",
    "            schemes.append(span)\n",
    "\n",
    "    return schemes\n",
    "\n",
    "    ## apply function\n",
    "    df2['Schemes1'] = df2.apply(lambda x:all_schemes(x.Sent,x.Check_Schemes), axis=1)"
   ]
  },
  {
   "source": [
    "But one thing I must point out here is that there were a lot more initiatives in the speeches that did not match our pattern. For example, in the year 2018, there were other initiatives too like “MUDRA”, ”Ujjwala”, ”Paris Agreement”, etc. So is there a better way to extract them?\n",
    "\n",
    "Remember how we looked at dependencies at the beginning of the article? Well, we are going to use those to make some rules to match the initiative name. But before making a rule, you need to understand how a sentence is structured, only then can you come up with a general rule to extract relevant information.\n",
    "\n",
    "To understand the structure of the sentence I am going to print the dependency graph of a sample example but in a tree fashion which gives a better intuition of the structure. Have a look below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = nlp(' Last year, I spoke about the Ujjwala programme , tgrough which, I am happy to report, 50 million free liquid-gas connections have been provided so far')\n",
    "# png = visualise_spacy_tree.create_png(doc)\n",
    "# display(Image(png))"
   ]
  },
  {
   "source": [
    "You must have got the idea by now that the initiative names are usually children of nodes that contain words like ‘initiative’, ‘programme’, etc. Based on this knowledge we can develop our own rule.\n",
    "\n",
    "The rule I am suggesting is pretty simple. Let me walk you through it:\n",
    "- I am going to look for tokens ins sentences that contain my initiative keywords\n",
    "- Then I am going to look at its subtree (or words dependent on it) using token.subtree and extract only those nodes/words that are proper nouns, since they are most likely going to contain the name of the initiative"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule to extract initiative name\n",
    "def sent_subtree(text):\n",
    "\n",
    "    # pattern match for schemes or initiatives\n",
    "    patterns = [r'\\b(?i)'+'plan'+r'\\b',\n",
    "           r'\\b(?i)'+'programme'+r'\\b',\n",
    "           r'\\b(?i)'+'scheme'+r'\\b',\n",
    "           r'\\b(?i)'+'campaign'+r'\\b',\n",
    "           r'\\b(?i)'+'initiative'+r'\\b',\n",
    "           r'\\b(?i)'+'conference'+r'\\b',\n",
    "           r'\\b(?i)'+'agreement'+r'\\b',\n",
    "           r'\\b(?i)'+'alliance'+r'\\b']\n",
    "\n",
    "    schemes = []\n",
    "    doc = nlp(text)\n",
    "    flag = 0\n",
    "    # if no initiative present in sentence\n",
    "    for pat in patterns:\n",
    "\n",
    "        if re.search(pat, text) != None:\n",
    "            flag = 1\n",
    "            break\n",
    "\n",
    "    if flag == 0:\n",
    "        return schemes\n",
    "\n",
    "    # iterating over sentence tokens\n",
    "    for token in doc:\n",
    "\n",
    "        for pat in patterns:\n",
    "                \n",
    "            # if we get a pattern match\n",
    "            if re.search(pat, token.text) != None:\n",
    "\n",
    "                word = ''\n",
    "                # iterating over token subtree\n",
    "                for node in token.subtree:\n",
    "                    # only extract the proper nouns\n",
    "                    if (node.pos_ == 'PROPN'):\n",
    "                        word += node.text+' '\n",
    "\n",
    "                if len(word)!=0:\n",
    "                    schemes.append(word)\n",
    "\n",
    "    return schemes      \n",
    "\n",
    "# derive initiatives\n",
    "df2['Schemes2'] = df2['Sent'].apply(sent_subtree)"
   ]
  },
  {
   "source": [
    "Out of 7000+ sentences, we were able to zero down to just 282 sentences that talked about initiatives. I looped over these outputs and below is how I would summarise the output:\n",
    "\n",
    "- There are a lot of different international initiatives or schemes that India has mentioned in its speeches. This goes to show that India has been an active member of the international community working towards building a better future by solving problems through these initiatives\n",
    "\n",
    "- Another point to highlight here is that the initiatives mentioned in the initial years have been more focused on those that concern the international community. However, during recent times, especially after 2014, a lot of domestic initiatives have been mentioned in the speeches like ‘Ayushman Bharat’, ‘Pradhan Mantri Jan Dhan Yojana’, etc. This shows a shift in how the country perceives its role in the community. By mentioning a lot of domestic initiatives, India has started to put more of the domestic work in front of the international community to witness and, probably, even follow in their footsteps\n",
    "\n",
    "Having said that, the results were definitely not perfect. There were instances when unwanted words were also getting extracted with the initiative names. But the output derived by making our own rules was definitely better than the ones derived by using SpaCy’s pattern matcher. This goes to show the flexibility we can achieve by making our own rules."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Finding Patterns in the Speeches\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list = []\n",
    "# df2 contains all sentences from all speeches\n",
    "for i in range(len(df2)):\n",
    "    sent = df2.loc[i,'Sent']\n",
    "    \n",
    "    if (',' not in sent) and (len(sent.split()) <= 15):\n",
    "        \n",
    "        year = df2.loc[i,'Year']\n",
    "        length = len(sent.split())\n",
    "        \n",
    "        dict1 = {'Year':year,'Sent':sent,'Len':length}\n",
    "        row_list.append(dict1)\n",
    "        \n",
    "# df with shorter sentences\n",
    "df3 = pd.DataFrame(columns=['Year','Sent',\"Len\"])\n",
    "df3 = pd.DataFrame(row_list)"
   ]
  },
  {
   "source": [
    "Write a simple function that will generate random sentences from this dataframe:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def rand_sent(df):\n",
    "    \n",
    "    index = randint(0, len(df))\n",
    "    print('Index = ',index)\n",
    "    doc = nlp(df.loc[index,'Sent'][1:])\n",
    "    displacy.render(doc, style='dep',jupyter=True)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "source": [
    "# function to check output percentage for a rule\n",
    "def output_per(df,out_col):\n",
    "    \n",
    "    result = 0\n",
    "    \n",
    "    for out in df[out_col]:\n",
    "        if len(out)!=0:\n",
    "            result+=1\n",
    "    \n",
    "    per = result/len(df)\n",
    "    per *= 100\n",
    "    \n",
    "    return per"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 56,
   "outputs": []
  },
  {
   "source": [
    "## Information Extraction #3 - Rule on Noun-Verb-Noun Phrases\n",
    "When you look at a sentence, it generally contains a subject (noun), action (verb), and an object (noun). The rest of the words are just there to give us additional information about the entities. Therefore, we can leverage this basic structure to extract the main bits of information from the sentence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for rule 1: noun(subject), verb, noun(object)\n",
    "def rule1(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        # if the token is a verb\n",
    "        if (token.pos_=='VERB'):\n",
    "            \n",
    "            phrase =''\n",
    "            \n",
    "            # only extract noun or pronoun subjects\n",
    "            for sub_tok in token.lefts:\n",
    "                \n",
    "                if (sub_tok.dep_ in ['nsubj','nsubjpass']) and (sub_tok.pos_ in ['NOUN','PROPN','PRON']):\n",
    "                    \n",
    "                    # add subject to the phrase\n",
    "                    phrase += sub_tok.text\n",
    "\n",
    "                    # save the root of the verb in phrase\n",
    "                    phrase += ' '+token.lemma_ \n",
    "\n",
    "                    # check for noun or pronoun direct objects\n",
    "                    for sub_tok in token.rights:\n",
    "                        \n",
    "                        # save the object in the phrase\n",
    "                        if (sub_tok.dep_ in ['dobj']) and (sub_tok.pos_ in ['NOUN','PROPN']):\n",
    "                                    \n",
    "                            phrase += ' '+sub_tok.text\n",
    "                            sent.append(phrase)\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22.916666666666664"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# create a df containing sentence and its output for rule 1\n",
    "row_list = []\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    \n",
    "    sent = df3.loc[i,'Sent']\n",
    "    year = df3.loc[i,'Year']\n",
    "    output = rule1(sent)\n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "    \n",
    "df_rule1 = pd.DataFrame(row_list)\n",
    "\n",
    "# rule 1 achieves 20% result on simple sentences\n",
    "output_per(df_rule1,'Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31.258741258741257"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "\n",
    "# create a df containing sentence and its output for rule 1\n",
    "row_list = []\n",
    "\n",
    "# df2 contains all the sentences from all the speeches\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    sent = df2.loc[i,'Sent']\n",
    "    year = df2.loc[i,'Year']\n",
    "    output = rule1(sent)\n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "    \n",
    "df_rule1_all = pd.DataFrame(row_list)\n",
    "\n",
    "# check rule1 output on complete speeches\n",
    "output_per(df_rule1_all,'Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting non-empty output rows\n",
    "df_show = pd.DataFrame(columns=df_rule1_all.columns)\n",
    "\n",
    "for row in range(len(df_rule1_all)):\n",
    "    \n",
    "    if len(df_rule1_all.loc[row,'Output'])!=0:\n",
    "        df_show = df_show.append(df_rule1_all.loc[row,:])\n",
    "\n",
    "# reset the index\n",
    "df_show.reset_index(inplace=True)\n",
    "df_show.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate subject, verb and object\n",
    "\n",
    "verb_dict = dict()\n",
    "dis_dict = dict()\n",
    "dis_list = []\n",
    "\n",
    "# iterating over all the sentences\n",
    "for i in range(len(df_show)):\n",
    "    \n",
    "    # sentence containing the output\n",
    "    sentence = df_show.loc[i,'Sent']\n",
    "    # year of the sentence\n",
    "    year = df_show.loc[i,'Year']\n",
    "    # output of the sentence\n",
    "    output = df_show.loc[i,'Output']\n",
    "    \n",
    "    # iterating over all the outputs from the sentence\n",
    "    for sent in output:\n",
    "        \n",
    "        # separate subject, verb and object\n",
    "        n1, v, n2 = sent.split()[:1], sent.split()[1], sent.split()[2:]\n",
    "        \n",
    "        # append to list, along with the sentence\n",
    "        dis_dict = {'Sent':sentence,'Year':year,'Noun1':n1,'Verb':v,'Noun2':n2}\n",
    "        dis_list.append(dis_dict)\n",
    "        \n",
    "        # counting the number of sentences containing the verb\n",
    "        verb = sent.split()[1]\n",
    "        if verb in verb_dict:\n",
    "            verb_dict[verb]+=1\n",
    "        else:\n",
    "            verb_dict[verb]=1\n",
    "\n",
    "df_sep = pd.DataFrame(dis_list)"
   ]
  },
  {
   "source": [
    "Let’s take a look at the top 10 most occurring verbs used in the sentences:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   Sent  Year         Noun1  \\\n",
       "77     We support the early convening of a world dis...  1974          [We]   \n",
       "134    India has consistently supported the peace ke...  1995       [India]   \n",
       "167    It was  in that spirit that we supported the ...  2009          [we]   \n",
       "195    India supports the expansion of both the perm...  1996       [India]   \n",
       "215    We support the efforts of the Secretary  Gene...  1996          [We]   \n",
       "263    My delegation would support the taking of fur...  1972  [delegation]   \n",
       "375    My delegation fully supports the adoption by ...  1979  [delegation]   \n",
       "410    We therefore support a revitalized and more e...  1998          [We]   \n",
       "487    We support the valiant efforts of the Palesti...  1983          [We]   \n",
       "492    We fully support the representative of the Se...  1983          [We]   \n",
       "563    We should certainly support every effort for ...  1980          [We]   \n",
       "617    My delegation supports the Secretary General ...  1989  [delegation]   \n",
       "620    India supports all efforts aimed at the peace...  1989       [India]   \n",
       "621    In conformity with the principle of universal...  1989       [India]   \n",
       "627    India supports all measures that would discou...  1989       [India]   \n",
       "636    This is one of the major items on the General...  1989       [India]   \n",
       "773    We support the Secretary General’s efforts to...  1993          [We]   \n",
       "823    The international community, through the Unit...  2007   [community]   \n",
       "831    As the world’s largest democracy, it was also...  2007       [India]   \n",
       "875    We fully support the sovereignty, unity and t...  1990          [We]   \n",
       "882    We support all efforts aimed at the peaceful ...  1990          [We]   \n",
       "883    In conformity with the principle of universal...  1990          [we]   \n",
       "992    India  strongly supports the elimination of c...  2013       [India]   \n",
       "994    India supports the early  realization of a so...  2013       [India]   \n",
       "995     The international community must support the...  2013   [community]   \n",
       "1021   We support the struggle of the Palestinian pe...  1987          [We]   \n",
       "1025   India supports the efforts of the Secretary G...  1987       [India]   \n",
       "1031   We support the desire of its people for peace...  1987          [We]   \n",
       "1037   We support the efforts of the Secretary Gener...  1987          [We]   \n",
       "1066   India supports the current campaign against t...  2001       [India]   \n",
       "1276   We would support any steps which may be sugge...  1970          [We]   \n",
       "1287   As regards the conference on the law of the s...  1970  [delegation]   \n",
       "1454   We shall support all measures to intensify an...  1973          [We]   \n",
       "1474   We support the initiative of the Food and Agr...  1973          [We]   \n",
       "1509   We see the United Nations as the forum in whi...  1997  [programmes]   \n",
       "1570   India does not support any separatist movemen...  1984       [India]   \n",
       "1578   We support the convening of an international ...  1984          [We]   \n",
       "1689   India has consistently supported efforts in t...  1976       [India]   \n",
       "1753   We support the multilateral negotiations now ...  2008          [We]   \n",
       "1825   We support the sovereignty, independence, ter...  1985          [We]   \n",
       "1854   We support the Middle East peace process and ...  2000          [We]   \n",
       "1984   We support the efforts of the United Nations ...  2012          [We]   \n",
       "1985   We support Palestine’s aspirations for enhanc...  2012          [We]   \n",
       "1986   We support Palestine’s aspirations for enhanc...  2012          [We]   \n",
       "1988   India supports the Government and people of A...  2012       [India]   \n",
       "2017   We support the exercise of the right by the p...  1986          [We]   \n",
       "2024   We support the efforts of the Special Represe...  1986          [We]   \n",
       "2028   At the same time, we support the struggle of ...  1986          [we]   \n",
       "2040   In this regard, we support the proposal made ...  1986          [we]   \n",
       "2044   We fully support the proposal of the eminent ...  1986          [We]   \n",
       "2068   It will support tele  education, telemedicine...  2005          [It]   \n",
       "2069   It will support tele  education, telemedicine...  2005          [It]   \n",
       "2118   India supports peace efforts that ensure the ...  1991       [India]   \n",
       "2188   India has always supported the aspirations of...  1988       [India]   \n",
       "2365    India has consistently supported the soverei...  1992       [India]   \n",
       "\n",
       "         Verb                     Noun2  \n",
       "77    support               [convening]  \n",
       "134   support              [activities]  \n",
       "167   support                [adoption]  \n",
       "195   support               [expansion]  \n",
       "215   support                 [efforts]  \n",
       "263   support                  [taking]  \n",
       "375   support                [adoption]  \n",
       "410   support                 [Nations]  \n",
       "487   support                 [efforts]  \n",
       "492   support          [representative]  \n",
       "563   support                  [effort]  \n",
       "617   support                 [General]  \n",
       "620   support                 [efforts]  \n",
       "621   support             [aspirations]  \n",
       "627   support                [measures]  \n",
       "636   support                [approach]  \n",
       "773   support                 [General]  \n",
       "823   support                 [efforts]  \n",
       "831   support           [establishment]  \n",
       "875   support             [sovereignty]  \n",
       "882   support                 [efforts]  \n",
       "883   support             [aspirations]  \n",
       "992   support             [elimination]  \n",
       "994   support             [realization]  \n",
       "995   support                  [people]  \n",
       "1021  support                [struggle]  \n",
       "1025  support                 [efforts]  \n",
       "1031  support                  [desire]  \n",
       "1037  support                 [efforts]  \n",
       "1066  support                [campaign]  \n",
       "1276  support                   [steps]  \n",
       "1287  support              [viewpoints]  \n",
       "1454  support                [measures]  \n",
       "1474  support              [initiative]  \n",
       "1509  support               [objective]  \n",
       "1570  support                [movement]  \n",
       "1578  support               [convening]  \n",
       "1689  support                 [efforts]  \n",
       "1753  support            [negotiations]  \n",
       "1825  support             [sovereignty]  \n",
       "1854  support                 [process]  \n",
       "1984  support                 [efforts]  \n",
       "1985  support               [Palestine]  \n",
       "1986  support  [Palestine, aspirations]  \n",
       "1988  support              [Government]  \n",
       "2017  support                [exercise]  \n",
       "2024  support                 [efforts]  \n",
       "2028  support                [struggle]  \n",
       "2040  support                [proposal]  \n",
       "2044  support                [proposal]  \n",
       "2068  support                    [tele]  \n",
       "2069  support         [tele, education]  \n",
       "2118  support                 [efforts]  \n",
       "2188  support             [aspirations]  \n",
       "2365  support             [sovereignty]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sent</th>\n      <th>Year</th>\n      <th>Noun1</th>\n      <th>Verb</th>\n      <th>Noun2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>77</th>\n      <td>We support the early convening of a world dis...</td>\n      <td>1974</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[convening]</td>\n    </tr>\n    <tr>\n      <th>134</th>\n      <td>India has consistently supported the peace ke...</td>\n      <td>1995</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[activities]</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>It was  in that spirit that we supported the ...</td>\n      <td>2009</td>\n      <td>[we]</td>\n      <td>support</td>\n      <td>[adoption]</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>India supports the expansion of both the perm...</td>\n      <td>1996</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[expansion]</td>\n    </tr>\n    <tr>\n      <th>215</th>\n      <td>We support the efforts of the Secretary  Gene...</td>\n      <td>1996</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>My delegation would support the taking of fur...</td>\n      <td>1972</td>\n      <td>[delegation]</td>\n      <td>support</td>\n      <td>[taking]</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>My delegation fully supports the adoption by ...</td>\n      <td>1979</td>\n      <td>[delegation]</td>\n      <td>support</td>\n      <td>[adoption]</td>\n    </tr>\n    <tr>\n      <th>410</th>\n      <td>We therefore support a revitalized and more e...</td>\n      <td>1998</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[Nations]</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>We support the valiant efforts of the Palesti...</td>\n      <td>1983</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>We fully support the representative of the Se...</td>\n      <td>1983</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[representative]</td>\n    </tr>\n    <tr>\n      <th>563</th>\n      <td>We should certainly support every effort for ...</td>\n      <td>1980</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[effort]</td>\n    </tr>\n    <tr>\n      <th>617</th>\n      <td>My delegation supports the Secretary General ...</td>\n      <td>1989</td>\n      <td>[delegation]</td>\n      <td>support</td>\n      <td>[General]</td>\n    </tr>\n    <tr>\n      <th>620</th>\n      <td>India supports all efforts aimed at the peace...</td>\n      <td>1989</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>621</th>\n      <td>In conformity with the principle of universal...</td>\n      <td>1989</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[aspirations]</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>India supports all measures that would discou...</td>\n      <td>1989</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[measures]</td>\n    </tr>\n    <tr>\n      <th>636</th>\n      <td>This is one of the major items on the General...</td>\n      <td>1989</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[approach]</td>\n    </tr>\n    <tr>\n      <th>773</th>\n      <td>We support the Secretary General’s efforts to...</td>\n      <td>1993</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[General]</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>The international community, through the Unit...</td>\n      <td>2007</td>\n      <td>[community]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>831</th>\n      <td>As the world’s largest democracy, it was also...</td>\n      <td>2007</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[establishment]</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>We fully support the sovereignty, unity and t...</td>\n      <td>1990</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[sovereignty]</td>\n    </tr>\n    <tr>\n      <th>882</th>\n      <td>We support all efforts aimed at the peaceful ...</td>\n      <td>1990</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>883</th>\n      <td>In conformity with the principle of universal...</td>\n      <td>1990</td>\n      <td>[we]</td>\n      <td>support</td>\n      <td>[aspirations]</td>\n    </tr>\n    <tr>\n      <th>992</th>\n      <td>India  strongly supports the elimination of c...</td>\n      <td>2013</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[elimination]</td>\n    </tr>\n    <tr>\n      <th>994</th>\n      <td>India supports the early  realization of a so...</td>\n      <td>2013</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[realization]</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>The international community must support the...</td>\n      <td>2013</td>\n      <td>[community]</td>\n      <td>support</td>\n      <td>[people]</td>\n    </tr>\n    <tr>\n      <th>1021</th>\n      <td>We support the struggle of the Palestinian pe...</td>\n      <td>1987</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[struggle]</td>\n    </tr>\n    <tr>\n      <th>1025</th>\n      <td>India supports the efforts of the Secretary G...</td>\n      <td>1987</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>1031</th>\n      <td>We support the desire of its people for peace...</td>\n      <td>1987</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[desire]</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>We support the efforts of the Secretary Gener...</td>\n      <td>1987</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>1066</th>\n      <td>India supports the current campaign against t...</td>\n      <td>2001</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[campaign]</td>\n    </tr>\n    <tr>\n      <th>1276</th>\n      <td>We would support any steps which may be sugge...</td>\n      <td>1970</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[steps]</td>\n    </tr>\n    <tr>\n      <th>1287</th>\n      <td>As regards the conference on the law of the s...</td>\n      <td>1970</td>\n      <td>[delegation]</td>\n      <td>support</td>\n      <td>[viewpoints]</td>\n    </tr>\n    <tr>\n      <th>1454</th>\n      <td>We shall support all measures to intensify an...</td>\n      <td>1973</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[measures]</td>\n    </tr>\n    <tr>\n      <th>1474</th>\n      <td>We support the initiative of the Food and Agr...</td>\n      <td>1973</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[initiative]</td>\n    </tr>\n    <tr>\n      <th>1509</th>\n      <td>We see the United Nations as the forum in whi...</td>\n      <td>1997</td>\n      <td>[programmes]</td>\n      <td>support</td>\n      <td>[objective]</td>\n    </tr>\n    <tr>\n      <th>1570</th>\n      <td>India does not support any separatist movemen...</td>\n      <td>1984</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[movement]</td>\n    </tr>\n    <tr>\n      <th>1578</th>\n      <td>We support the convening of an international ...</td>\n      <td>1984</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[convening]</td>\n    </tr>\n    <tr>\n      <th>1689</th>\n      <td>India has consistently supported efforts in t...</td>\n      <td>1976</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>1753</th>\n      <td>We support the multilateral negotiations now ...</td>\n      <td>2008</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[negotiations]</td>\n    </tr>\n    <tr>\n      <th>1825</th>\n      <td>We support the sovereignty, independence, ter...</td>\n      <td>1985</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[sovereignty]</td>\n    </tr>\n    <tr>\n      <th>1854</th>\n      <td>We support the Middle East peace process and ...</td>\n      <td>2000</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[process]</td>\n    </tr>\n    <tr>\n      <th>1984</th>\n      <td>We support the efforts of the United Nations ...</td>\n      <td>2012</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>1985</th>\n      <td>We support Palestine’s aspirations for enhanc...</td>\n      <td>2012</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[Palestine]</td>\n    </tr>\n    <tr>\n      <th>1986</th>\n      <td>We support Palestine’s aspirations for enhanc...</td>\n      <td>2012</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[Palestine, aspirations]</td>\n    </tr>\n    <tr>\n      <th>1988</th>\n      <td>India supports the Government and people of A...</td>\n      <td>2012</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[Government]</td>\n    </tr>\n    <tr>\n      <th>2017</th>\n      <td>We support the exercise of the right by the p...</td>\n      <td>1986</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[exercise]</td>\n    </tr>\n    <tr>\n      <th>2024</th>\n      <td>We support the efforts of the Special Represe...</td>\n      <td>1986</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>2028</th>\n      <td>At the same time, we support the struggle of ...</td>\n      <td>1986</td>\n      <td>[we]</td>\n      <td>support</td>\n      <td>[struggle]</td>\n    </tr>\n    <tr>\n      <th>2040</th>\n      <td>In this regard, we support the proposal made ...</td>\n      <td>1986</td>\n      <td>[we]</td>\n      <td>support</td>\n      <td>[proposal]</td>\n    </tr>\n    <tr>\n      <th>2044</th>\n      <td>We fully support the proposal of the eminent ...</td>\n      <td>1986</td>\n      <td>[We]</td>\n      <td>support</td>\n      <td>[proposal]</td>\n    </tr>\n    <tr>\n      <th>2068</th>\n      <td>It will support tele  education, telemedicine...</td>\n      <td>2005</td>\n      <td>[It]</td>\n      <td>support</td>\n      <td>[tele]</td>\n    </tr>\n    <tr>\n      <th>2069</th>\n      <td>It will support tele  education, telemedicine...</td>\n      <td>2005</td>\n      <td>[It]</td>\n      <td>support</td>\n      <td>[tele, education]</td>\n    </tr>\n    <tr>\n      <th>2118</th>\n      <td>India supports peace efforts that ensure the ...</td>\n      <td>1991</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[efforts]</td>\n    </tr>\n    <tr>\n      <th>2188</th>\n      <td>India has always supported the aspirations of...</td>\n      <td>1988</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[aspirations]</td>\n    </tr>\n    <tr>\n      <th>2365</th>\n      <td>India has consistently supported the soverei...</td>\n      <td>1992</td>\n      <td>[India]</td>\n      <td>support</td>\n      <td>[sovereignty]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "# support verb\n",
    "df_sep[df_sep['Verb']=='support']"
   ]
  },
  {
   "source": [
    "## Information Extraction #4 - Rule on Adjective Noun Structure\n",
    "In the previous rule that we made, we extracted the noun subjects and objects, but the information did not feel complete. This is because many nouns have an adjective or a word with a compound dependency that augments the meaning of a noun. Extracting these along with the noun will give us better information about the subject and the object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The code for this rule is simple, but let me walk you through how it works:\n",
    "\n",
    "- We look for tokens that have a Noun POS tag and have subject or object dependency\n",
    "- Then we look at the child nodes of these tokens and append it to the phrase only if it modifies the noun"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for rule 2\n",
    "def rule2(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    pat = []\n",
    "    \n",
    "    # iterate over tokens\n",
    "    for token in doc:\n",
    "        phrase = ''\n",
    "        # if the word is a subject noun or an object noun\n",
    "        if (token.pos_ == 'NOUN')\\\n",
    "            and (token.dep_ in ['dobj','pobj','nsubj','nsubjpass']):\n",
    "            \n",
    "            # iterate over the children nodes\n",
    "            for subtoken in token.children:\n",
    "                # if word is an adjective or has a compound dependency\n",
    "                if (subtoken.pos_ == 'ADJ') or (subtoken.dep_ == 'compound'):\n",
    "                    phrase += subtoken.text + ' '\n",
    "                    \n",
    "            if len(phrase)!=0:\n",
    "                phrase += token.text\n",
    "             \n",
    "        if  len(phrase)!=0:\n",
    "            pat.append(phrase)\n",
    "        \n",
    "    \n",
    "    return pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df containing sentence and its output for rule 2\n",
    "row_list = []\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    \n",
    "    sent = df3.loc[i,'Sent']\n",
    "    year = df3.loc[i,'Year']\n",
    "    # rule\n",
    "    output = rule2(sent)\n",
    "    \n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "\n",
    "df_rule2 = pd.DataFrame(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "76.6013986013986"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "# create a df containing sentence and its output for rule 2\n",
    "row_list = []\n",
    "\n",
    "# df2 contains all the sentences from all the speeches\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    sent = df2.loc[i,'Sent']\n",
    "    year = df2.loc[i,'Year']\n",
    "    output = rule2(sent)\n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "    \n",
    "df_rule2_all = pd.DataFrame(row_list)\n",
    "\n",
    "# check rule output on complete speeches\n",
    "output_per(df_rule2_all,'Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting non-empty outputs\n",
    "df_show2 = pd.DataFrame(columns=df_rule2_all.columns)\n",
    "\n",
    "for row in range(len(df_rule2_all)):\n",
    "    \n",
    "    if len(df_rule2_all.loc[row,'Output'])!=0:\n",
    "        df_show2 = df_show2.append(df_rule2_all.loc[row,:])\n",
    "\n",
    "# reset the index\n",
    "df_show2.reset_index(inplace=True)\n",
    "df_show2.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule2_mod(text,index):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    phrase = ''\n",
    "    \n",
    "    for token in doc:\n",
    "        \n",
    "        if token.i == index:\n",
    "            \n",
    "            for subtoken in token.children:\n",
    "                if (subtoken.pos_ == 'ADJ'):\n",
    "                    phrase += ' '+subtoken.text\n",
    "            break\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule 1 modified function\n",
    "def rule1_mod(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "        # root word\n",
    "        if (token.pos_=='VERB'):\n",
    "            \n",
    "            phrase =''\n",
    "            \n",
    "            # only extract noun or pronoun subjects\n",
    "            for sub_tok in token.lefts:\n",
    "                \n",
    "                if (sub_tok.dep_ in ['nsubj','nsubjpass']) and (sub_tok.pos_ in ['NOUN','PROPN','PRON']):\n",
    "                    \n",
    "                    # look for subject modifier\n",
    "                    adj = rule2_mod(text,sub_tok.i)\n",
    "                    \n",
    "                    phrase += adj + ' ' + sub_tok.text\n",
    "\n",
    "                    # save the root word of the word\n",
    "                    phrase += ' '+token.lemma_ \n",
    "\n",
    "                    # check for noun or pronoun direct objects\n",
    "                    for sub_tok in token.rights:\n",
    "                        \n",
    "                        if (sub_tok.dep_ in ['dobj']) and (sub_tok.pos_ in ['NOUN','PROPN']):\n",
    "                            \n",
    "                            # look for object modifier\n",
    "                            adj = rule2_mod(text,sub_tok.i)\n",
    "                            \n",
    "                            phrase += adj+' '+sub_tok.text\n",
    "                            sent.append(phrase)\n",
    "            \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "31.258741258741257"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "# create a df containing sentence and its output for modified rule 1\n",
    "row_list = []\n",
    "\n",
    "# df2 contains all the sentences from all the speeches\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    sent = df2.loc[i,'Sent']\n",
    "    year = df2.loc[i,'Year']\n",
    "    output = rule1_mod(sent)\n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "    \n",
    "df_rule1_mod_all = pd.DataFrame(row_list)\n",
    "# check rule1 output on complete speeches\n",
    "output_per(df_rule1_mod_all,'Output')"
   ]
  },
  {
   "source": [
    "## Information Extraction #5 - Rule on Prepositions\n",
    "Thank god for prepositions! They tell us where or when something is in a relationship with something else. For example, The people of India believe in the principles of the United Nations. Clearly extracting phrases including prepositions will give us a lot of information from the sentence. This is exactly what we are going to achieve with this rule.\n",
    "\n",
    "Let’s try to understand how this rule works by going over it on a sample sentence – “India has once again shown faith in democracy.”\n",
    "\n",
    "- We iterate over all the tokens looking for prepositions. For example, in this sentence\n",
    "- On encountering a preposition, we check if it has a headword that is a noun. For example, the word faith in this sentence\n",
    "- Then we look at the child tokens of the preposition token falling on its right side. For example, the word democracy\n",
    "\n",
    "This should finally extract the phrase **faith in democracy** from the sentence. Have a look at the dependency graph of the sentence below:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule 3 function\n",
    "def rule3(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "\n",
    "        # look for prepositions\n",
    "        if token.pos_=='ADP':\n",
    "\n",
    "            phrase = ''\n",
    "            \n",
    "            # if its head word is a noun\n",
    "            if token.head.pos_=='NOUN':\n",
    "                \n",
    "                # append noun and preposition to phrase\n",
    "                phrase += token.head.text\n",
    "                phrase += ' '+token.text\n",
    "\n",
    "                # check the nodes to the right of the preposition\n",
    "                for right_tok in token.rights:\n",
    "                    # append if it is a noun or proper noun\n",
    "                    if (right_tok.pos_ in ['NOUN','PROPN']):\n",
    "                        phrase += ' '+right_tok.text\n",
    "                \n",
    "                if len(phrase)>2:\n",
    "                    sent.append(phrase)\n",
    "                \n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49.44852941176471"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "\n",
    "# create a df containing sentence and its output for rule 3\n",
    "row_list = []\n",
    "\n",
    "for i in range(len(df3)):\n",
    "    \n",
    "    sent = df3.loc[i,'Sent']\n",
    "    year = df3.loc[i,'Year']\n",
    "    \n",
    "    # rule\n",
    "    output = rule3(sent)\n",
    "    \n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "\n",
    "df_rule3 = pd.DataFrame(row_list)\n",
    "# output percentage for rule 3\n",
    "output_per(df_rule3,'Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "74.7132867132867"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "# create a df containing sentence and its output for rule 3\n",
    "row_list = []\n",
    "\n",
    "# df2 contains all the sentences from all the speeches\n",
    "for i in range(len(df2)):\n",
    "    \n",
    "    sent = df2.loc[i,'Sent']\n",
    "    year = df2.loc[i,'Year']\n",
    "    output = rule3(sent)\n",
    "    dict1 = {'Year':year,'Sent':sent,'Output':output}\n",
    "    row_list.append(dict1)\n",
    "    \n",
    "df_rule3_all = pd.DataFrame(row_list)\n",
    "# check rule3 output on complete speeches\n",
    "output_per(df_rule3_all,'Output')"
   ]
  },
  {
   "source": [
    "74% of the total sentences match this pattern. Let’s separate the preposition from the nouns and see what kind of information we were able to extract:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select non-empty outputs\n",
    "df_show3 = pd.DataFrame(columns=df_rule3_all.columns)\n",
    "\n",
    "for row in range(len(df_rule3_all)):\n",
    "    \n",
    "    if len(df_rule3_all.loc[row,'Output'])!=0:\n",
    "        df_show3 = df_show3.append(df_rule3_all.loc[row,:])\n",
    "\n",
    "# reset the index\n",
    "df_show3.reset_index(inplace=True)\n",
    "df_show3.drop('index',axis=1,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate noun, preposition and noun\n",
    "\n",
    "prep_dict = dict()\n",
    "dis_dict = dict()\n",
    "dis_list = []\n",
    "\n",
    "# iterating over all the sentences\n",
    "for i in range(len(df_show3)):\n",
    "    \n",
    "    # sentence containing the output\n",
    "    sentence = df_show3.loc[i,'Sent']\n",
    "    # year of the sentence\n",
    "    year = df_show3.loc[i,'Year']\n",
    "    # output of the sentence\n",
    "    output = df_show3.loc[i,'Output']\n",
    "    \n",
    "    # iterating over all the outputs from the sentence\n",
    "    for sent in output:\n",
    "        \n",
    "        # separate subject, verb and object\n",
    "        n1, p, n2 = sent.split()[0], sent.split()[1], sent.split()[2:]\n",
    "        \n",
    "        # append to list, along with the sentence\n",
    "        dis_dict = {'Sent':sentence,'Year':year,'Noun1':n1,'Preposition':p,'Noun2':n2}\n",
    "        dis_list.append(dis_dict)\n",
    "        \n",
    "        # counting the number of sentences containing the verb\n",
    "        prep = sent.split()[1]\n",
    "        if prep in prep_dict:\n",
    "            prep_dict[prep]+=1\n",
    "        else:\n",
    "            prep_dict[prep]=1\n",
    "\n",
    "df_sep3= pd.DataFrame(dis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('of', 7083),\n",
       " ('in', 1422),\n",
       " ('for', 896),\n",
       " ('to', 602),\n",
       " ('on', 454),\n",
       " ('with', 277),\n",
       " ('between', 163),\n",
       " ('by', 143),\n",
       " ('from', 117),\n",
       " ('against', 93)]"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "sort = sorted(prep_dict.items(), key = lambda d:(d[1],d[0]), reverse=True)\n",
    "sort[:10]"
   ]
  },
  {
   "source": [
    "We look at certain prepositions to explore the sentences in detail. For example, the preposition ‘against’ can give us information about what India does not support:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    Sent  Year       Noun1  \\\n",
       "623     In order to strengthen the international lega...  2009       fight   \n",
       "823     India has a unique record of supporting Unite...  1996  activities   \n",
       "1065    We must ensure that our solidarity in the com...  1972    struggle   \n",
       "1257    A terrorist is a terrorist, and anyone who co...  2015      crimes   \n",
       "1320    Africa is a region with which we have histori...  2015    struggle   \n",
       "...                                                  ...   ...         ...   \n",
       "11361   That is why I urge that we strengthen the int...  1999   consensus   \n",
       "11362   India has called for a comprehensive internat...  1999  convention   \n",
       "11417   From the earliest days of our struggle agains...  1999    struggle   \n",
       "11472   If this can only be a step by step process, t...  1999  safeguards   \n",
       "11513   Therefore, may I urge the Assembly to conside...  1999  convention   \n",
       "\n",
       "      Preposition             Noun2  \n",
       "623       against       [terrorism]  \n",
       "823       against       [apartheid]  \n",
       "1065      against  [discrimination]  \n",
       "1257      against        [humanity]  \n",
       "1320      against     [colonialism]  \n",
       "...           ...               ...  \n",
       "11361     against       [terrorism]  \n",
       "11362     against       [terrorism]  \n",
       "11417     against     [imperialism]  \n",
       "11472     against             [use]  \n",
       "11513     against       [terrorism]  \n",
       "\n",
       "[93 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sent</th>\n      <th>Year</th>\n      <th>Noun1</th>\n      <th>Preposition</th>\n      <th>Noun2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>623</th>\n      <td>In order to strengthen the international lega...</td>\n      <td>2009</td>\n      <td>fight</td>\n      <td>against</td>\n      <td>[terrorism]</td>\n    </tr>\n    <tr>\n      <th>823</th>\n      <td>India has a unique record of supporting Unite...</td>\n      <td>1996</td>\n      <td>activities</td>\n      <td>against</td>\n      <td>[apartheid]</td>\n    </tr>\n    <tr>\n      <th>1065</th>\n      <td>We must ensure that our solidarity in the com...</td>\n      <td>1972</td>\n      <td>struggle</td>\n      <td>against</td>\n      <td>[discrimination]</td>\n    </tr>\n    <tr>\n      <th>1257</th>\n      <td>A terrorist is a terrorist, and anyone who co...</td>\n      <td>2015</td>\n      <td>crimes</td>\n      <td>against</td>\n      <td>[humanity]</td>\n    </tr>\n    <tr>\n      <th>1320</th>\n      <td>Africa is a region with which we have histori...</td>\n      <td>2015</td>\n      <td>struggle</td>\n      <td>against</td>\n      <td>[colonialism]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11361</th>\n      <td>That is why I urge that we strengthen the int...</td>\n      <td>1999</td>\n      <td>consensus</td>\n      <td>against</td>\n      <td>[terrorism]</td>\n    </tr>\n    <tr>\n      <th>11362</th>\n      <td>India has called for a comprehensive internat...</td>\n      <td>1999</td>\n      <td>convention</td>\n      <td>against</td>\n      <td>[terrorism]</td>\n    </tr>\n    <tr>\n      <th>11417</th>\n      <td>From the earliest days of our struggle agains...</td>\n      <td>1999</td>\n      <td>struggle</td>\n      <td>against</td>\n      <td>[imperialism]</td>\n    </tr>\n    <tr>\n      <th>11472</th>\n      <td>If this can only be a step by step process, t...</td>\n      <td>1999</td>\n      <td>safeguards</td>\n      <td>against</td>\n      <td>[use]</td>\n    </tr>\n    <tr>\n      <th>11513</th>\n      <td>Therefore, may I urge the Assembly to conside...</td>\n      <td>1999</td>\n      <td>convention</td>\n      <td>against</td>\n      <td>[terrorism]</td>\n    </tr>\n  </tbody>\n</table>\n<p>93 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "# 'against'\n",
    "df_sep3[df_sep3['Preposition'] == 'against']"
   ]
  },
  {
   "source": [
    "Skimming over the nouns, some important phrases like:\n",
    "\n",
    "* efforts against proliferation\n",
    "* fight against terrorism, action against terrorism, the war against terrorism\n",
    "* discrimination against women\n",
    "* war against poverty\n",
    "* struggle against colonialism\n",
    "\n",
    "… and so on. This should give us a fair idea about which sentences we want to explore in detail. For example, efforts against proliferation talk about efforts towards nuclear disarmament. Or the sentence on the struggle against colonialism talks about the historical links between India and Africa borne out of their common struggle against colonialism."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' It is that period in which dynasties vanished and revolutions swept empires off the face of ancient lands'"
      ]
     },
     "metadata": {},
     "execution_count": 78
    }
   ],
   "source": [
    "df_sep3.loc[11272, 'Sent']"
   ]
  },
  {
   "source": [
    "As you can see, prepositions give us an important relationship between two nouns. And with a little domain knowledge, we can easily sieve through the vast data and determine what India supports or does not support, among other things.\n",
    "\n",
    "But the output seems a bit incomplete. For example, in the sentence efforts against proliferation, what kind of proliferation are we talking about? Certainly, we need to include the modifiers attached to the nouns in the phrase as we did in Information Extraction #4. This would definitely increase the comprehensibility of the extracted phrase.\n",
    "\n",
    "This rule can be easily modified to include the new change. I have created a new function to extract the noun modifiers for nouns that we extracted from Information Extraction #4"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule 0\n",
    "def rule0(text, index):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "        \n",
    "    token = doc[index]\n",
    "    \n",
    "    entity = ''\n",
    "    \n",
    "    for sub_tok in token.children:\n",
    "        if (sub_tok.dep_ in ['compound','amod']):\n",
    "            entity += sub_tok.text+' '\n",
    "    \n",
    "    entity += token.text\n",
    "\n",
    "    return entity"
   ]
  },
  {
   "source": [
    "All we have to do is call this function whenever we encounter a noun in our phrase:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule 3 function\n",
    "def rule3_mod(text):\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    sent = []\n",
    "    \n",
    "    for token in doc:\n",
    "\n",
    "        if token.pos_=='ADP':\n",
    "\n",
    "            phrase = ''\n",
    "            if token.head.pos_=='NOUN':\n",
    "                \n",
    "                # appended rule\n",
    "                append = rule0(text, token.head.i)\n",
    "                if len(append)!=0:\n",
    "                    phrase += append\n",
    "                else:  \n",
    "                    phrase += token.head.text\n",
    "                phrase += ' '+token.text\n",
    "\n",
    "                for right_tok in token.rights:\n",
    "                    if (right_tok.pos_ in ['NOUN','PROPN']):\n",
    "                        \n",
    "                        right_phrase = ''\n",
    "                        # appended rule\n",
    "                        append = rule0(text, right_tok.i)\n",
    "                        if len(append)!=0:\n",
    "                            right_phrase += ' '+append\n",
    "                        else:\n",
    "                            right_phrase += ' '+right_tok.text\n",
    "                            \n",
    "                        phrase += right_phrase\n",
    "                \n",
    "                if len(phrase)>2:\n",
    "                    sent.append(phrase)\n",
    "                \n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}